# 电商秒杀项目说明

该项目是基于Spring Cloud的微服务架构搭建的一个高并发，可横向扩展的分布式集群部署项目。

本项目在设计之初便考虑到了秒杀系统在短时间内的突发并发高，系统负载压力大，竞争资源有限，数据库锁冲突严重，数据库分库分表数据一致性等问题。本项目引入了限流、消息队列、分布式锁，分布式事务控制等组件，实现了突发高流量的平稳应对，有效解决了有限资源竞争，数据库并发访问竞争，分布式数据库数据一致性等问题。

## 技术栈

### Spring Cloud

Spring Cloud作为本项目的主要使用框架，实现了项目的微服务化，能够方便的实现集群部署与横向拓展。

#### Spring Cloud Gateway

Gateway是在Spring生态系统之上构建的API网关服务，为微服务架构提供—种简单有效的统一的API路由管理方式。

#### Spring Cloud OpenFeign

OpenFeign实现了微服务调用负载均衡。通过feign定义服务绑定接口且以声明式的方法 ，优雅而简单的实现了服务调用。

#### Spring Cloud Stream

构建消息驱动微服务的框架，为消息中间件提供自动化的配置实现。

### Spring Cloud Alibaba

将 Spring Cloud 应用接入阿里分布式应用解决方案，通过阿里中间件来迅速搭建分布式应用系统。

#### Nacos

Nacos服务注册中心，实现服务注册发现

Nacos服务配置中心，为分布式系统中的外部化配置提供服务器端和客户端支持。

#### Sentinel

Sentinel实现服务监控与流控。以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。

#### Seata

Seata提供分布式事务的解决方案，作为分布式一致性中间件保证数据的一致性。

### MySql

提供数据持久化服务。

### MyBatis-Plus

MyBatis增强工具，提供无侵入、损耗小的CRUD操作。

### Redis

内存中的数据结构存储系统。提供数据缓存、分布式锁等功能。

### RabbitMQ

一套开源（MPL）的消息队列服务软件。

### Nginx

一个高性能的HTTP和反向代理web服务器。

### Docker

容器化部署。

## 项目技术难点

### 微服务服务治理

在传统的RPC远程调用框架中，管理每个服务与服务之间依赖关系比较复杂，管理比较复杂，所以需要使用服务治理，管理服务于服务之间依赖关系，可以实现服务调用、负载均衡、容错等，实现服务发现与注册。

#### Nacos集群实现服务注册发现与配置中心

服务注册中心的核心功能：

1. 各个微服务在启动时，将自己的网络地址等信息注册到注册中心，注册中心存储这些数据。
2. 服务消费者从注册中心查询服务提供者的地址，并通过该地址调用服务提供者的接口。
3. 各个微服务与注册中心使用一定机制（例如心跳）通信。如果注册中心与某微服务长时间无法通信，就会注销该实例。
4. 微服务网络地址发送变化（例如实例增加或IP变动等）时，会重新注册到注册中心。这样，服务消费者就无需人工修改提供者的网络地址了。

采用服务中心来管理服务之间的依赖关系，可以实现各微服务之间依赖的解耦。服务调用方不再需要对服务提供者的ip进行硬编码，只需要通过服务注册中心请求可用的服务提供者地址，便可完成服务调用。因此，基于服务中心的微服务治理模式，我们可以方便的对微服务进行横向扩展（只需要新增一个服务实例并将其注册进服务注册中心即可）。

<img src="项目说明.assets/image-20211214144827938.png" alt="image-20211214144827938" style="zoom: 67%;" />

Nacos实现了AP和CP模式的支持，本项目中使用AP模式实现服务的注册发现，服务实例通过nacos-client注册，并保持心跳上报。

Nacos支持对服务注册客户端进行动态配置，十分方便的解决了微服务的配置发布问题。

本项目构建Nacos采用三个Nacos实例构成集群保证其高可用，使用Nginx实现集群的负载均衡，使用Mysql实现配置信息持久化服务。

![img](image/项目说明/1639447178021.png)

#### 远程调用与负载均衡

微服务之间的远程调用由OpenFegin实现，负载均衡由Spring Cloud LoadBalancer提供。

### RabbitMQ消息队列控制数据库并发访问冲突

由于秒杀系统的高并发特点，会导致数据库访问的并发冲突问题。当有多个线程对数据库同时进行并发读写的时候，可能会导致超卖的问题发生。

![](image/项目说明/1639447478396.png)

本项目使用消息队列来对并发请求进行控制，避免图示的并发冲突：

![](image/项目说明/1639447550896.png)

消息队列的优点对业务进行了解耦，除了数据库之外，其他对下单请求感兴趣的业务系统，例如数据分析，日志记录等都可以订阅下单请求的消息。因此，本项目的秒杀服务架构如下：

![](image/项目说明/1639447670788.png)

在实际生产环境中，需要考虑消息队列宕机的可能性，所以在生产环境中应该配置RabbitMQ集群来实现高可用。

### 高并发下的Sentinel和Redis限流

秒杀系统具有短时高并发的特点。在真实的秒杀系统中，商品的种类和库存相较于一般的电商系统都较少，导致大部分流量集中在少量商品中；同时，由于秒杀系统的商品稀缺，同一位客户可能会对同一商品多次提交下单请求，而且恶意刷单的请求比较多，所以系统接收到的无效请求及非法请求较多。因此，对请求进行合理的限流，大部分请求并没有必要到达消息队列与数据库，只放行少量请求进入可以大大减轻服务端的压力。

#### Sentinel

利用Sentinel在服务实例层面对QPS(Query Per Second)进行限制。在短时高并发的流量冲击下，我们应该对我们的服务实例进行保护，避免其因突发流量而崩溃。

##### 流量削峰

本项目在后端服务入口（Spring Cloud Gateway）处进行流量削峰，对进入Gateway的请求进行流量控制，使用匀速排队模式，对超过阈值的请求以固定速率来处理消息：

![](image/项目说明/1639448608139.png)

通过流量削峰，使以突刺状来到的请求变得平缓，系统以稳定的速度，逐步处理这些请求，以起到“削峰填谷”的效果。

##### 快速失败

由于秒杀商品的稀缺性，当明知一款商品库存只有几十或几百件却有成千上万名用户下单的时候，让所有用户请求都进入消息队列和数据库显然是不合理的。因此利用Sentinel对QPS进行限制，让其对超过阈值的请求直接返回快速失败（商品已售罄、服务繁忙等）信息，来达到流量控制的目的，使得较少的实例也可以处理较高的并发请求。

#### Redis

利用redis在操作层面对流量进行限制。对实例的访问数量和非法访问进行控制，保证服务的安全与稳定。

##### 基于Redis缓存库存的流量限制

由于秒杀商品的库存总量较少，除了前文提到的使用Sentinel对QPS进行限制外，我们还应该对到达消息队列的请求总量进行控制。

本项目利用Redis缓存库存进行总量限制，每一个服务端实例缓存 `n*k`个请求限额，其中n是某一商品的初始库存数量，k是参数，可根据实际应用场景进行调整。超过请求限额后，服务端实例便拒绝所有到达的对该商品的下单请求。因而最终到达消息队列和数据库的请求总数不会超过 `n*k*M`个（M为服务实例数）。实际工程中，因为有客户可能会出现支付超时导致释放库存的情况，系统需要通知限流器接受少量新的请求。

##### 基于Redis分布式锁的非法访问控制

秒杀系统由于商品稀缺，同一位客户可能会对同一商品多次提交下单请求，而且恶意刷单的请求比较多，所以系统接收到的无效请求及非法请求较多**。**

利用Redis分布式锁机制可以对用户的非法访问进行有效控制。

Redis为单进程单线程模式，采用队列模式将并发访问变成串行访问，且多客户端对Redis的连接并不存在竞争关系。其次Redis提供一些命令SETNX，GETSET，可以方便实现分布式锁机制。

我们可以对用户ID，token，IP源等信息进行加锁，阻止短时间内相同参数的并发访问，从而阻止用户的恶意刷单。

本项目采用对用户ID加锁，利用Redis的分布式锁机制，多个服务实例需要先获取某个用户ID的锁，再对该用户提供下单服务，否则直接返回错误信息。

锁释放与锁重入：由于此处Redis分布式锁仅仅是对用户进行并发控制，所以不需要解锁操作，只需要对Redis锁设置自动过期时间（本项目设置为5秒），便可达成单一用户的下单请求并发控制功能，同时并不会出现死锁等问题。

### 数据库分库与分布式事务控制

Mysql单实例性能存在上限，当数据量增加时需要分库分表，由此引入多数据源的全局事务控制问题。

#### 数据库分库

本项目在设计之初便考虑到mysql性能问题，因而将不同的表（订单、库存、用户）放入不同的数据库以便于日后拓展。

数据库分库后便会引入全局事物数据一致性问题。由于一个秒杀订单存在插入订单、扣减库存、访问用户等多个操作，如果某个操作发送异常，为保证事物原子性，需要全局事务回滚，本项目中引入seata完成全局事务控制。

#### Seata

提供无侵入自动补偿的事务模式：在微服务中对数据源的操作进行代理，实现分布式事务控制的功能。

##### 分布式事务的原子性

Seata的分布式事务处理过程由一ID+三组件构成：

- Transaction ID XID 全局唯一的事务ID
- 三组件
  - TC (Transaction Coordinator) - 事务协调者：维护全局和分支事务的状态，驱动全局事务提交或回滚。
  - TM (Transaction Manager) - 事务管理器：定义全局事务的范围：开始全局事务、提交或回滚全局事务。
  - RM (Resource Manager) - 资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。

![image-20211214142814568](项目说明.assets/image-20211214142814568.png)

处理过程：

- TM向TC申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的XID；
- XID在微服务调用链路的上下文中传播；
- RM向TC注册分支事务，将其纳入XID对应全局事务的管辖；
- TM向TC发起针对XID的全局提交或回滚决议；
- TC调度XID下管辖的全部分支事务完成提交或回滚请求。

由此，当调用链路中的微服务发生异常时，能由全局事务回滚保证事物的原子性。

##### 分布式事务的隔离性

Seata分布式事务隔离性由两阶段协议保证：

- 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。
- 二阶段：
  - 事务提交，提交异步化，非常快速地完成。
  - 事务异常，回滚通过一阶段的回滚日志进行反向补偿。

**写隔离**

- 一阶段本地事务提交前，需要确保先拿到 **全局锁** 。
- 拿不到 **全局锁** ，不能提交本地事务。
- 拿 **全局锁** 的尝试被限制在一定范围内，超出范围将放弃，并回滚本地事务，释放本地锁。

以一个示例来说明：

两个全局事务 tx1 和 tx2，分别对 a 表的 m 字段进行更新操作，m 的初始值 1000。

tx1 先开始，开启本地事务，拿到本地锁，更新操作 m = 1000 - 100 = 900。本地事务提交前，先拿到该记录的 **全局锁** ，本地提交释放本地锁。 tx2 后开始，开启本地事务，拿到本地锁，更新操作 m = 900 - 100 = 800。本地事务提交前，尝试拿该记录的 **全局锁** ，tx1 全局提交前，该记录的全局锁被 tx1 持有，tx2 需要重试等待 **全局锁** 。

![image-20211214143335428](项目说明.assets/image-20211214143335428.png)

tx1 二阶段全局提交，释放 **全局锁** 。tx2 拿到 **全局锁** 提交本地事务。

![image-20211214143347387](项目说明.assets/image-20211214143347387.png)

如果 tx1 的二阶段全局回滚，则 tx1 需要重新获取该数据的本地锁，进行反向补偿的更新操作，实现分支的回滚。

此时，如果 tx2 仍在等待该数据的 **全局锁**，同时持有本地锁，则 tx1 的分支回滚会失败。分支的回滚会一直重试，直到 tx2 的 **全局锁** 等锁超时，放弃 **全局锁** 并回滚本地事务释放本地锁，tx1 的分支回滚最终成功。

因为整个过程 **全局锁** 在 tx1 结束前一直是被 tx1 持有的，所以不会发生 **脏写** 的问题。

**读隔离**

在数据库本地事务隔离级别 **读已提交（Read Committed）** 或以上的基础上，Seata（AT 模式）的默认全局隔离级别是 **读未提交（Read Uncommitted）** 。

如果应用在特定场景下，必需要求全局的 **读已提交** ，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。

![image-20211214143441614](项目说明.assets/image-20211214143441614.png)

SELECT FOR UPDATE 语句的执行会申请 **全局锁** ，如果 **全局锁** 被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到 **全局锁** 拿到，即读取的相关数据是 **已提交** 的，才返回。

出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。

## 项目架构

### 服务入口

外部请求经过nginx反向代理映射到不同的服务网关，由服务网关路由到不同的具体微服务提供服务。

![image-20211214150600358](项目说明.assets/image-20211214150600358.png)

#### Nginx

nginx实现反向代理，对外提供统一的服务访问接口。如需对nginx配置高可用，则需在外部通过DNS等方式将请求映射到多个nignx实例上。

同时，nginx兼任静态资源服务器功能，为外部请求的静态资源提供服务。

### Gateway

服务网关，为微服务调用提供路由，同时提供合法性验证、鉴权等功能。

### 秒杀微服务

本项目考虑到秒杀服务的特点，采用了读写分离的微服务架构，使得实际生产环境中能根据系统实际性能消耗，拓展相应的部分。

![image-20211214151347085](项目说明.assets/image-20211214151347085.png)

#### 数据读服务

提供商品、库存、订单等查询服务，采用redis缓存使得只有少量请求会真正进入数据库。

#### 数据写服务

秒杀订单生成的核心逻辑部分。由多个数据限流/订单生成模块，在sentinel的支持下对QPS进行流控，在redis分布式锁的支持下剔除非法访问，在redis缓存的支持下完成总量控制。

订单生成后进入消息队列，订单处理模块消费消息队列中的消息，完成并发控制，对数据库进行读写。

### 数据库服务

由Seata代理的数据库服务，完成了分库环境下的全局事务的支持。

![image-20211214151807718](项目说明.assets/image-20211214151807718.png)

### 项目整体架构图

![architecture](项目说明.assets/architecture.png)

