# 电商秒杀项目模拟测试

测试本项目的实际功能，检查高并发访问下限流器是否正常工作，是否存在并发访问冲突（是否存在超卖问题）。

测试本项目的并发量，在当前部署环境下进行并发压测，测试高压状态下是否正常工作。

部署服务实例表：

![image-20211215160847498](模拟测试.assets/image-20211215160847498.png)

测试工具：jmiter

## 并发竞争测试与限流控制测试

测试在消息队列的支持下，是否会存在并发访问冲突问题。

### 无消息队列与限流器的并发访问冲突演示

首先直连订单处理模块，演示在无消息队列控制的时候超卖的情况。

#### 测试用例

在后台管理系统中添加相应测试用例：

![image-20211215161454355](模拟测试.assets/image-20211215161454355.png)

在数据库中新的测试用例已添加，库存50：

![image-20211215161544509](模拟测试.assets/image-20211215161544509.png)

使用jmeter创建500个线程访问/create/makeSeckill接口创建订单，每个线程循环两次：

![image-20211215162547502](模拟测试.assets/image-20211215162547502.png)

#### 测试结果

观察seckill的库存：

![image-20211215162057487](模拟测试.assets/image-20211215162057487.png)

可以发现显示库存还剩41，明显与预期不符，我们使用了500*2个请求，应该能够完全售空。

再查看订单列表：

![image-20211215162214136](模拟测试.assets/image-20211215162214136.png)

![image-20211215162316049](模拟测试.assets/image-20211215162316049.png)

可以看到实际售出954份，超卖现象十分严重。

同时，所有请求都进入数据库，数据库压力极大，所有请求执行完毕共耗时25s左右，用户体验极差。

### 消息队列下的并发访问控制以及限流器和分布式锁控制下的流量控制

#### 测试用例

将库存重新添加回50继续进行测试：

![image-20211215162731158](模拟测试.assets/image-20211215162731158.png)

这时使用消息队列中间件，同时在限流器与分布式锁的控制下进行测试：

![image-20211215162842102](模拟测试.assets/image-20211215162842102.png)

jmeter开启1000个线程5次循环并发访问

![image-20211215162941737](模拟测试.assets/image-20211215162941737.png)

每个线程使用自己的线程ID作为userID

#### 测试结果

![image-20211215163723679](模拟测试.assets/image-20211215163723679.png)

![image-20211215163809982](模拟测试.assets/image-20211215163809982.png)

![image-20211215163706572](模拟测试.assets/image-20211215163706572.png)

此时可以清楚的看到，并不存在超卖的问题，生成订单数量为50份。

同时查看服务负载情况：

![image-20211215163555783](模拟测试.assets/image-20211215163555783.png)

![image-20211215163606123](模拟测试.assets/image-20211215163606123.png)

可以看到，大量的请求进入了gateway到达了seckill-restrictor，单机QPS峰值为612，集群峰值为1216。

但查看消息队列的请求统计：

![image-20211215163623075](模拟测试.assets/image-20211215163623075.png)

可以看到，请求峰值QPS仅为20，大大减轻了数据库的压力。

同时可以发现，此处消息总数为100，符合redis限流器`n*k*M=50*1*2`的预期。（库存50，参数k=1，两台实例，所以限流器会放入100个请求）

查看seckill-maker8001日志：

![image-20211215164427058](模拟测试.assets/image-20211215164427058.png)

可以看到，由于我们有5次循环，所以每个用户（每个线程）会有大量重复请求，都在分布式锁中被拦截下来了。

同时，获取到分布式锁的请求也由于限制器库存限制50个被耗尽而被限制器拦截。

可见，大量请求并没有进入到消息队列中去操作数据库，而是被拦截了下来，这大大降低了服务端的压力。

## 并发压测

### 2000线程5循环

gateway负载峰值为1754QPS

![image-20211215165138032](模拟测试.assets/image-20211215165138032.png)

seckill-maker订单限制器QPS峰值为1752

![image-20211215165148477](模拟测试.assets/image-20211215165148477.png)

![img](模拟测试.assets/{O1C]}_D8PP6D1Q%B1@J.png)

错误率为0.68%，服务端峰值平均响应时间为117ms。

### 4000线程5循环

采用两台计算机分担（每台计算机2000线程访问）

![image-20211215170332463](模拟测试.assets/image-20211215170332463.png)

![image-20211215170343728](模拟测试.assets/image-20211215170343728.png)

gateway峰值QPS1606，seckill-maker订单生成模块峰值QPS1576

测试机1报告

![image-20211215170612069](模拟测试.assets/image-20211215170612069.png)

错误率4.85%

测试机2报告

![image-20211215170705778](模拟测试.assets/image-20211215170705778.png)

错误率3.76%

### 测试结论

QPS1500-2000应该为单机极限了，受限于gateway的单实例部署，访问QPS存在上限。

实际生产环境中应根据业务需求横向拓展部署gateway多实例用nginx负载均衡反向代理。